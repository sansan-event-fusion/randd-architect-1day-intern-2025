"""
ã¿ã¡ã³å› â€” äººè„ˆãƒŠãƒ“ã‚²ãƒ¼ã‚·ãƒ§ãƒ³ãƒ„ãƒ¼ãƒ«
(è¦ªå¯†åº¦ + é›»è©± + å½¹è· + ååˆºäº¤æ›æ—¥ï¼çµŒéæ—¥æ•°)
------------------------------------------------------------
NEW (2025-06-14)
  â€¢ ã€Œé€£çµ¡ã—ãŸã„ç›¸æ‰‹ã€ã‚’å½¹è·ã§ã‚‚é¸æŠå¯
  â€¢ å½¹è·ã‚’æŒ‡å®šã—ãŸå ´åˆã€ãã®å½¹è·ã«è©²å½“ã™ã‚‹â€œå…¨å“¡åˆ†â€ã®æœ€çŸ­ãƒ‘ã‚¹ã‚’ä¸€è¦§è¡¨ç¤º
------------------------------------------------------------
"""

# ------------------------------------------------------------
# Imports
# ------------------------------------------------------------
import os
from concurrent.futures import ThreadPoolExecutor
from datetime import date

import networkx as nx
import pandas as pd
import requests
import streamlit as st
from requests.adapters import HTTPAdapter, Retry

# ------------------------------------------------------------
# Page config
# ------------------------------------------------------------
st.set_page_config(
    page_title="ã¿ã¡ã³å› | äººè„ˆãƒŠãƒ“ã‚²ãƒ¼ã‚·ãƒ§ãƒ³ãƒ„ãƒ¼ãƒ«",
    layout="wide",
    initial_sidebar_state="expanded",
)
st.title("ğŸ¤– ã¿ã¡ã³å›")

# ------------------------------------------------------------
# Constants & session
# ------------------------------------------------------------
BASE_URL = "https://circuit-trial.stg.rd.ds.sansan.com/api"
CARDS_ENDPOINT = f"{BASE_URL}/cards/"
CONTACTS_ENDPOINT = f"{BASE_URL}/contacts/"
DEFAULT_LIMIT = 100
TIMEOUT = int(os.getenv("API_TIMEOUT", "30"))
TODAY = pd.Timestamp(date.today())  # tz-naive

_session = requests.Session()
_session.mount("https://", HTTPAdapter(max_retries=Retry(total=3, backoff_factor=1.5)))
_executor = ThreadPoolExecutor(max_workers=2)


# ------------------------------------------------------------
# Helper functions
# ------------------------------------------------------------
@st.cache_data(ttl=3600, max_entries=20)
def fetch_all(endpoint: str) -> pd.DataFrame:
    rows, off = [], 0
    while True:
        r = _session.get(endpoint, params={"limit": DEFAULT_LIMIT, "offset": off}, timeout=TIMEOUT)
        r.raise_for_status()
        if not (chunk := r.json()):
            break
        rows.extend(chunk)
        off += DEFAULT_LIMIT
    return pd.DataFrame(rows)


@st.cache_data(ttl=3600, max_entries=20)
def read_csv_async(f) -> pd.DataFrame:
    return pd.read_csv(f)


def acquire(endpoint: str, label: str) -> pd.DataFrame:
    with st.spinner(f"{label} ã‚’å–å¾—ä¸­â€¦"):
        try:
            return fetch_all(endpoint)
        except Exception as e:
            up = st.sidebar.file_uploader(f"{label} CSV ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type="csv")
            if up:
                return _executor.submit(read_csv_async, up).result()
            st.error(f"{label} ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
            st.stop()


def badge(text: str, color: str) -> str:
    return (
        f'<span style="background:{color};color:#fff;padding:2px 6px;border-radius:6px;font-weight:bold;">{text}</span>'
    )


def intimacy_label(w: int, max_w: int) -> str:
    r = w / max_w if max_w else 0
    return "å¼·" if r >= 0.7 else ("æ™®" if r >= 0.4 else "å¼±")


# ------------------------------------------------------------
# Load data
# ------------------------------------------------------------
cards_df = acquire(CARDS_ENDPOINT, "ååˆºãƒ‡ãƒ¼ã‚¿")
contacts_df = acquire(CONTACTS_ENDPOINT, "ååˆºäº¤æ›å±¥æ­´")
st.success(f"ååˆº {len(cards_df):,} ä»¶ / äº¤æ›å±¥æ­´ {len(contacts_df):,} ä»¶ å–å¾—")

# ---- key columns
PHONE_COL = "phone_number" if "phone_number" in cards_df.columns else None
POSITION_COL = "position" if "position" in cards_df.columns else None

cols = ["full_name", "company_name"]
for c in [PHONE_COL, POSITION_COL]:
    if c:
        cols.append(c)

user_info: dict[str, dict[str, str]] = cards_df.set_index("user_id")[cols].fillna("").to_dict("index")
all_companies: list[str] = sorted(cards_df["company_name"].dropna().unique().tolist())

# contacts preprocessing (tz â†’ naive)
contacts_df["created_at"] = pd.to_datetime(contacts_df["created_at"], errors="coerce").dt.tz_localize(None)

# ------------------------------------------------------------
# Sidebar UI
# ------------------------------------------------------------
st.sidebar.subheader("ã¿ã¡ã³å›ã®è¨­å®š")

# ã‚ãªãŸé¸æŠ
st.sidebar.write("### ğŸ§‘â€ğŸ’¼ ã‚ãªãŸ")
my_company = st.sidebar.selectbox("æ‰€å±ä¼æ¥­", options=all_companies)
my_candidates = cards_df.query("company_name == @my_company and full_name.notna()")
my_user_id: str = st.sidebar.selectbox(
    "ã‚ãªãŸã®åå‰",
    options=my_candidates["user_id"].tolist(),
    format_func=lambda x: user_info[x]["full_name"],
)
st.sidebar.info(f"ã‚ãªãŸ: {user_info[my_user_id]['full_name']} ({my_company})")

# ç›¸æ‰‹ä¼šç¤¾ & å½¹è·ãƒ•ã‚£ãƒ«ã‚¿
st.sidebar.write("### ğŸ“ é€£çµ¡ã—ãŸã„ç›¸æ‰‹")
tg_company = st.sidebar.selectbox("ç›¸æ‰‹ã®æ‰€å±ä¼æ¥­", options=all_companies)

# å½¹è·ãƒ•ã‚£ãƒ«ã‚¿ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
pos_options = []
if POSITION_COL:
    pos_options = sorted(cards_df.loc[cards_df["company_name"] == tg_company, POSITION_COL].dropna().unique())
select_role = None
if pos_options:
    select_role = st.sidebar.selectbox("å½¹è·ã§çµã‚Šè¾¼ã‚€ (ä»»æ„)", options=["(æŒ‡å®šãªã—)"] + pos_options)

# ç›¸æ‰‹ãƒ¦ãƒ¼ã‚¶ãƒ¼é¸æŠï¼ˆå½¹è·ãƒ•ã‚£ãƒ«ã‚¿ãŒãªã„ or æŒ‡å®šãªã—ã®å ´åˆã®ã¿ï¼‰
if not pos_options or select_role == "(æŒ‡å®šãªã—)":
    tg_candidates = cards_df.query("company_name == @tg_company and full_name.notna()")
    tg_user_id: str = st.sidebar.selectbox(
        "ç›¸æ‰‹ã®åå‰",
        options=tg_candidates["user_id"].tolist(),
        format_func=lambda x: user_info[x]["full_name"],
    )
    target_user_ids = [tg_user_id]
else:
    # å½¹è·ãŒæŒ‡å®šã•ã‚ŒãŸå ´åˆï¼šè©²å½“è€…å…¨å“¡
    target_user_ids = cards_df.query("company_name == @tg_company and position == @select_role and full_name.notna()")[
        "user_id"
    ].tolist()
    st.sidebar.info(f"å½¹è· '{select_role}' ã®è©²å½“è€… {len(target_user_ids)} å")

# ------------------------------------------------------------
# Validate
# ------------------------------------------------------------
if my_user_id in target_user_ids:
    st.warning("è‡ªåˆ†ã¨ç›¸æ‰‹ãŒåŒã˜ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚’å«ã‚“ã§ã„ã¾ã™ã€‚é™¤å¤–ã—ã¾ã™ã€‚")
    target_user_ids = [uid for uid in target_user_ids if uid != my_user_id]
if not target_user_ids:
    st.stop()

# ------------------------------------------------------------
# Build graph once
# ------------------------------------------------------------
G = nx.Graph()
for _, r in contacts_df.iterrows():
    a, b = r["owner_user_id"], r["user_id"]
    if a and b and a != b:
        G.add_edge(a, b, weight=G[a][b]["weight"] + 1 if G.has_edge(a, b) else 1)


# ------------------------------------------------------------
# Helper: first exchange date
# ------------------------------------------------------------
def first_exchange(uid: str) -> pd.Timestamp | None:
    filt = ((contacts_df["owner_user_id"] == my_user_id) & (contacts_df["user_id"] == uid)) | (
        (contacts_df["owner_user_id"] == uid) & (contacts_df["user_id"] == my_user_id)
    )
    s = contacts_df.loc[filt, "created_at"].dropna()
    return s.min() if not s.empty else None


# ------------------------------------------------------------
# Path calculation & display
# ------------------------------------------------------------
def build_path_df(path: list[str]) -> tuple[pd.DataFrame, str]:
    # max weight for intimacy scaling
    ws = [G[path[i]][path[i + 1]]["weight"] for i in range(len(path) - 1)] if len(path) > 1 else []
    max_w = max(ws) if ws else 1

    rows = []
    for i, uid in enumerate(path):
        info = user_info.get(uid, {})
        exch = first_exchange(uid)
        rows.append(
            {
                "ãƒ¦ãƒ¼ã‚¶ãƒ¼ID": uid,
                "æ°å": info.get("full_name", "ä¸æ˜"),
                "ä¼šç¤¾": info.get("company_name", "ä¸æ˜"),
                "å½¹è·": info.get(POSITION_COL, "") if POSITION_COL else "",
                "é›»è©±": info.get(PHONE_COL, "") if PHONE_COL else "",
                "ååˆºäº¤æ›æ—¥": exch.strftime("%Y-%m-%d") if exch is not None else "",
                "äº¤æ›ã‹ã‚‰ã®æ—¥æ•°": (TODAY - exch).days if exch is not None else "",
                "è¦ªå¯†åº¦": intimacy_label(G[uid][path[i + 1]]["weight"], max_w) if i < len(path) - 1 else "",
            }
        )
    df = pd.DataFrame(rows)

    # badge path
    b_list = []
    for uid in path:
        name = user_info.get(uid, {}).get("full_name", uid)
        if uid == my_user_id:
            b_list.append(badge(name, "#3b82f6"))
        elif uid in target_user_ids:
            b_list.append(badge(name, "#ef4444"))
        else:
            b_list.append(badge(name, "#f59e0b"))
    arrow_html = " â¡ï¸ ".join(b_list)
    return df, arrow_html


# --- Iterate over targets -----------------------------------
for tgt in target_user_ids:
    try:
        path_nodes = nx.shortest_path(G, my_user_id, tgt)
    except nx.NetworkXNoPath:
        st.error(f"âŒ {user_info[tgt]['full_name']} ã¨ã®ãƒ‘ã‚¹ã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
        continue

    df, arrow_html = build_path_df(path_nodes)

    with st.expander(
        f"ğŸ“ {user_info[tgt]['full_name']} ã¸ã®ãƒ«ãƒ¼ãƒˆï¼ˆ{len(path_nodes) - 1} ãƒ›ãƒƒãƒ—ï¼‰",
        expanded=len(target_user_ids) == 1,
    ):
        st.markdown(arrow_html, unsafe_allow_html=True)
        st.table(df)
        dl = df.to_csv(index=False).encode("utf-8-sig")
        st.download_button("CSV ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", dl, file_name=f"michibikun_path_{tgt}.csv", mime="text/csv")
